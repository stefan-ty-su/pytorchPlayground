{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchmetrics\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import wandb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.EMNIST(\n",
    "    root = \"data\",\n",
    "    split = \"balanced\",\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = transforms.ToTensor()\n",
    ")\n",
    "\n",
    "test_data = torchvision.datasets.EMNIST(\n",
    "    root = \"data\",\n",
    "    split = \"balanced\",\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    epochs = 5,\n",
    "    in_features = 1,\n",
    "    classes = 47,\n",
    "    kernels = [32, 64],\n",
    "    batch_size = 32,\n",
    "    learning_rate = 0.001,\n",
    "    dataset=\"EMNIST\",\n",
    "    architecture=\"ON\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class eMNISTModel(nn.Module):\n",
    "\n",
    "    def __init__(self, input_features: int, kernels: list[int], output_features: int):\n",
    "        super().__init__()\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_features, out_channels=kernels[0],\n",
    "                      kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=kernels[0], out_channels=kernels[0],\n",
    "                      kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=kernels[0], out_channels=kernels[1],\n",
    "                      kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=kernels[1], out_channels=kernels[1],\n",
    "                      kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=kernels[-1]*49, out_features=output_features)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.tensor) -> torch.tensor:\n",
    "        return self.classifier(self.conv_block2(self.conv_block1(x)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class eMNISTModelTraditional(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_features:int, kernels: list[int], output_features: int):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features = input_features, out_features = kernels[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features = kernels[0], out_features = kernels[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features = kernels[1], out_features = output_features)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.tensor) -> torch.tensor:\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_pipeline(\"EMNIST\", eMNISTModel(1, [32, 64], 47), train_data, test_data, config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = test_data.classes\n",
    "test_dataloader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    batch_data, batch_label = next(iter(test_dataloader))\n",
    "    rand_idx = torch.randint(0, 32, (1,1)).item()\n",
    "    rand_idx = 12\n",
    "    img, label = batch_data[rand_idx], batch_label[rand_idx]\n",
    "    print(img.shape)\n",
    "    logit = model(img.unsqueeze(1).to(device))\n",
    "    pred = torch.softmax(logit, dim=1).argmax(dim=1)\n",
    "    plt.imshow(img.squeeze())\n",
    "    plt.title(f\"Act: {class_names[label]} | Pred: {class_names[pred]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
